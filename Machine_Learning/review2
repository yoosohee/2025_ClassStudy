{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyezotz9BYjOV5FcJ0jFld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoosohee/2025_ClassStudy/blob/main/Machine_Learning/review2\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4X0IqGAhN92"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# -------------------------------\n",
        "# T1 0 1 2 3 4 T2\n",
        "# -------------------------------\n",
        "\n",
        "\n",
        "class RandomWalk():\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_internal_states=5,        # 종료 상태를 제외한 내부 상태 개수\n",
        "            transition_reward=0.0,        # 일반적인 상태 전이 보상\n",
        "            left_terminal_reward=0.0,     # 왼쪽 종료 상태로 이동하는 행동\n",
        "                                          # 수행 시 받는 보상\n",
        "            right_terminal_reward=1.0     # 오른쪽 종료 상태로 이동하는 행동\n",
        "                                          # 수행 시 받는 보상\n",
        "    ):\n",
        "        self.__version__ = \"0.0.1\"\n",
        "\n",
        "        self.num_internal_states = num_internal_states\n",
        "\n",
        "        self.num_states = num_internal_states + 2\n",
        "        self.STATES = [i for i in range(num_internal_states)]\n",
        "        self.TERMINAL_STATES = ['T1', 'T2']\n",
        "\n",
        "        # 모든 가능한 행동\n",
        "        self.ACTION_LEFT = 0\n",
        "        self.ACTION_RIGHT = 1\n",
        "        self.ACTION_SYMBOLS = [\"\\u2190\", \"\\u2192\"]\n",
        "\n",
        "        # 종료 상태를 제외한 임의의 상태에서 왼쪽 이동 또는 오른쪽 이동\n",
        "        self.ACTIONS = [\n",
        "            self.ACTION_LEFT,\n",
        "            self.ACTION_RIGHT\n",
        "        ]\n",
        "        self.NUM_ACTIONS = len(self.ACTIONS)\n",
        "\n",
        "        # 시작 상태 위치\n",
        "        self.START_STATE = self.STATES[int(num_internal_states / 2)]\n",
        "\n",
        "        self.transition_reward = transition_reward\n",
        "\n",
        "        self.left_terminal_reward = left_terminal_reward\n",
        "\n",
        "        self.right_terminal_reward = right_terminal_reward\n",
        "\n",
        "        self.current_state = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_state = self.START_STATE\n",
        "        return self.current_state\n",
        "\n",
        "    def moveto(self, state):\n",
        "        self.current_state = state\n",
        "\n",
        "    def get_next_state(self, state, action):\n",
        "        if state in self.TERMINAL_STATES:\n",
        "            next_state = state\n",
        "        else:\n",
        "            if action == self.ACTION_LEFT:\n",
        "                if state == 0:\n",
        "                    next_state = 'T1'\n",
        "                else:\n",
        "                    next_state = state - 1\n",
        "            elif action == self.ACTION_RIGHT:\n",
        "                if state == self.num_internal_states - 1:\n",
        "                    next_state = 'T2'\n",
        "                else:\n",
        "                    next_state = state + 1\n",
        "            else:\n",
        "                raise ValueError()\n",
        "\n",
        "        return next_state\n",
        "\n",
        "    def get_reward(self, state, next_state):\n",
        "        if next_state == 'T1':\n",
        "            reward = self.left_terminal_reward\n",
        "        elif next_state == 'T2':\n",
        "            reward = self.right_terminal_reward\n",
        "        else:\n",
        "            reward = self.transition_reward\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_state_action_probability(self, state, action):\n",
        "        next_state = self.get_next_state(state, action)\n",
        "\n",
        "        reward = self.get_reward(state, next_state)\n",
        "        prob = 1.0\n",
        "\n",
        "        return next_state, reward, prob\n",
        "\n",
        "    # take @action in @state\n",
        "    # @return: (reward, new state)\n",
        "    def step(self, action):\n",
        "        next_state = self.get_next_state(\n",
        "            state=self.current_state, action=action\n",
        "        )\n",
        "\n",
        "        reward = self.get_reward(self.current_state, next_state)\n",
        "\n",
        "        self.current_state = next_state\n",
        "\n",
        "        if self.current_state in self.TERMINAL_STATES:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        return next_state, reward, done, None\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(self.__str__(), end=\"\\n\\n\")\n",
        "\n",
        "    def get_random_action(self):\n",
        "        return random.choice(self.ACTIONS)\n",
        "\n",
        "    def __str__(self):\n",
        "        randomwalk_str = \"\"\n",
        "        randomwalk_str += \" T1 \" + \" \".join(\n",
        "            [\"{0}\".format(i) for i in range(self.num_internal_states)]\n",
        "        ) + \" T2\\n\"\n",
        "\n",
        "        if self.current_state in self.STATES:\n",
        "            blank = \"    \" + \"  \" * self.current_state\n",
        "        elif self.current_state == 'T1':\n",
        "            blank = \" \"\n",
        "        elif self.current_state == 'T2':\n",
        "            blank = \"  \" + \"  \" * (self.num_internal_states + 1)\n",
        "        else:\n",
        "            raise ValueError()\n",
        "\n",
        "        randomwalk_str += blank + \"*\"\n",
        "\n",
        "        return randomwalk_str"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def main():\n",
        "  env = RandomWalk()\n",
        "  env.reset()\n",
        "  print(\"reset\")\n",
        "  env.render()\n",
        "\n",
        "  done = False\n",
        "  total_steps=0\n",
        "  while not done:\n",
        "    total_steps += 1\n",
        "    action = env.get_random_action()\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    print(\"action: {0}, reward: {1}, total_steps: {3}\".format(\n",
        "        env.ACTION_SYMBOLS[action],\n",
        "        reward, done, total_steps\n",
        "    ))\n",
        "    env.render()\n",
        "\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "LnS3CqMVhdta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKCFpLQ_jgn7",
        "outputId": "ead922d5-59cc-4c46-e2d0-15e9e54dd894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reset\n",
            " T1 0 1 2 3 4 T2\n",
            "        *\n",
            "\n",
            "action: →, reward: 0.0, total_steps: 1\n",
            " T1 0 1 2 3 4 T2\n",
            "          *\n",
            "\n",
            "action: →, reward: 0.0, total_steps: 2\n",
            " T1 0 1 2 3 4 T2\n",
            "            *\n",
            "\n",
            "action: →, reward: 1.0, total_steps: 3\n",
            " T1 0 1 2 3 4 T2\n",
            "              *\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xODbQlzWjkIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}